import os
import random

import numpy as np
import pandas as pd
import torch
from catboost import CatBoostClassifier
from sklearn.metrics import f1_score
# from sklearn.model_selection import train_test_split
import optuna
from optuna.integration import CatBoostPruningCallback
import warnings
import json

warnings.simplefilter('ignore')


def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def load_npy_for_cb(df, path):
    data = []
    for name in df.record_name:
        with open(f"{path}{name}.npy", "rb") as f:
            y = np.load(f, allow_pickle=True)
            row = np.std(y, axis=1)
            data.append(row)
    data = np.stack(data)
    data = pd.DataFrame(np.stack(data), columns=list(range(data.shape[-1])))
    data["record_name"] = df["record_name"]
    return data


def processing(gts, meta, cat_f, path, is_train=True):
    gts = gts.merge(meta, on='record_name')

    gts = gts.fillna(0)
    gts.age = gts.age.astype(int)

    for c in cat_f:
        gts[c] = gts[c].astype(str)
    gts.age = gts.age.astype(int)
    gts.ecg_id = gts.ecg_id.astype(int)
    gts.patient_id = gts.patient_id.astype(int)
    gts.scp_codes = gts.scp_codes.astype(str)
    if is_train:
        data = load_npy_for_cb(gts, path)
    else:
        data = load_npy_for_cb(gts, path)
    gts = gts.merge(data, on='record_name')
    if is_train:
        return gts.drop(columns=['myocard', 'record_name', 'recording_date', 'filename_lr', 'filename_hr', 'ecg_id', 'patient_id']), gts[
            'myocard']
    return gts.drop(columns=['myocard', 'record_name', 'recording_date', 'filename_lr', 'filename_hr', 'ecg_id', 'patient_id'])


def objective(trial: optuna.Trial) -> float:
    param = {
        "objective": trial.suggest_categorical("objective", ["Logloss", "CrossEntropy"]),
        "colsample_bylevel": trial.suggest_float("colsample_bylevel", 0.01, 0.1, log=True),
        "depth": trial.suggest_int("depth", 1, 12),
        "boosting_type": trial.suggest_categorical("boosting_type", ["Ordered", "Plain"]),
        "bootstrap_type": trial.suggest_categorical(
            "bootstrap_type", ["Bayesian", "Bernoulli", "MVS"]
        ),
        "used_ram_limit": "10gb",
        "eval_metric": 'F1'
    }

    if param["bootstrap_type"] == "Bayesian":
        param["bagging_temperature"] = trial.suggest_float("bagging_temperature", 0, 10)
    elif param["bootstrap_type"] == "Bernoulli":
        param["subsample"] = trial.suggest_float("subsample", 0.1, 1, log=True)
    with open('config.json', 'r') as f:
        config = json.load(f)
    pruning_callback = CatBoostPruningCallback(trial, "F1")
    df = pd.read_csv(config['train_gts'])
    df_test = pd.read_csv('catboost_std.csv')
    meta_test = pd.read_csv(config['test_meta'])
    meta = pd.read_csv(config['train_meta'])
    cat_f = ['age', 'sex', 'height', 'weight', 'nurse', 'site', 'device', 'heart_axis',
             'infarction_stadium1', 'infarction_stadium2', 'validated_by', 'second_opinion',
             'initial_autogenerated_report', 'validated_by_human', 'baseline_drift', 'static_noise',
             'burst_noise', 'electrodes_problems', 'extra_beats', 'pacemaker', 'strat_fold', 'group']

    X_train, y_train = processing(df, meta, cat_f, config['train_path'])
    X_val, y_val = processing(df_test, meta_test, cat_f, config['test_path'])
    # X, y = processing(df, meta, cat_f)
    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)

    model = CatBoostClassifier(**param)
    model.fit(X_train, y_train, eval_set=(X_val, y_val), cat_features=cat_f,
              text_features=['report', 'scp_codes'],
              verbose=0,
              early_stopping_rounds=100,
              callbacks=[pruning_callback])
    pruning_callback.check_pruned()
    return f1_score(y_val, model.predict(X_val))


if __name__ == "__main__":
    seed_everything(42)
    study = optuna.create_study(
        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction="maximize"
    )
    study.optimize(objective, timeout=3600)

    print("Number of finished trials: {}".format(len(study.trials)))

    print("Best trial:")
    trial = study.best_trial

    print("  Value: {}".format(trial.value))
    with open('catboost_all_data.json', 'w') as f:
        json.dump(study.best_params, f)
    print("  Params: ")
    for key, value in trial.params.items():
        print("    {}: {}".format(key, value))
